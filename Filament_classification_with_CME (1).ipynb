{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Filament_classification with CME.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi1ScZMyW3Jr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"/content/filaments_cmes.csv\")"
      ],
      "metadata": {
        "id": "MfNkXTeYXGxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_needed=data[['dur_min','X','Y','RATING','TYPE_corrected','ERUPTION_corrected','TWIST_crctd','WRITHE_crctd','THREADS_crctd','CAVITY_corrected','CME_crctd']]"
      ],
      "metadata": {
        "id": "UPiTUndYXJtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jUOf0kBkXMMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##one hot encoding to features\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "OHE=OneHotEncoder(handle_unknown='ignore')"
      ],
      "metadata": {
        "id": "L-JK4J2LXV1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##dropping Nan\n",
        "data_processed=data_needed.dropna()"
      ],
      "metadata": {
        "id": "RMXYgNHy8oIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_neeeded1=pd.get_dummies(data_processed,columns=['TYPE_corrected','ERUPTION_corrected','TWIST_crctd','WRITHE_crctd','THREADS_crctd','CAVITY_corrected'])"
      ],
      "metadata": {
        "id": "-Bvk1fkyZPHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VTUq49YVI-6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_neeeded1.shape"
      ],
      "metadata": {
        "id": "Q36eDfTS9B1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##statistics of each feature\n",
        "#3duration with eruption\n",
        "import seaborn as sns\n",
        "sns.catplot(x=\"TYPE_corrected\", y=\"dur_min\",hue='CME_crctd', kind=\"bar\", data=data_processed)"
      ],
      "metadata": {
        "id": "L9JPS83fTpxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_processed.columns"
      ],
      "metadata": {
        "id": "IfrK4Jy5iFun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.catplot(x=\"CME_crctd\", kind=\"count\", palette=\"ch:.25\", data=data_processed)"
      ],
      "metadata": {
        "id": "LMpHFizjh24L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sEyy0z9kh7zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##testlabel encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "data_neeeded1['CME_crctd'] = LE.fit_transform(data_neeeded1['CME_crctd'])\n",
        "\n"
      ],
      "metadata": {
        "id": "E7JsnqIwBcly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into train and test\n",
        "xdata=data_neeeded1[['dur_min','X','Y','RATING','TYPE_corrected_AR',\t'TYPE_corrected_IP',\t'TYPE_corrected_PC',\t'TYPE_corrected_QS',\t'ERUPTION_corrected_C',\t'ERUPTION_corrected_F',\t'ERUPTION_corrected_N',\t'ERUPTION_corrected_P',\t'TWIST_crctd_A',\t'TWIST_crctd_N',\t'TWIST_crctd_Y',\t'WRITHE_crctd_N',\t'WRITHE_crctd_Y',\t'THREADS_crctd_N',\t'THREADS_crctd_Y',\t'CAVITY_corrected_D',\t'CAVITY_corrected_N',\t'CAVITY_corrected_Y']]\n",
        "ydata=data_neeeded1[['CME_crctd']]"
      ],
      "metadata": {
        "id": "o2SbnPEIQ0Vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xdata=data_neeeded1[['dur_min']]\n",
        "ydata=data_neeeded1[['CME_crctd']]"
      ],
      "metadata": {
        "id": "bauSkB7viSmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after feature selection\n",
        "xdata=data_neeeded1[['ERUPTION_corrected_C','ERUPTION_corrected_F', 'ERUPTION_corrected_N', 'ERUPTION_corrected_P','RATING','dur_min','TYPE_corrected_AR', 'TYPE_corrected_IP',\n",
        "       'TYPE_corrected_PC', 'TYPE_corrected_QS','THREADS_crctd_N', 'THREADS_crctd_Y']]\n",
        "ydata=data_neeeded1[['CME_crctd']]  "
      ],
      "metadata": {
        "id": "Chkkpl9v3qSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##featureranking\n",
        "from pandas import read_csv\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# load data\n",
        "\n",
        "model = ExtraTreesClassifier(n_estimators=10)\n",
        "model.fit(xdata, ydata)\n",
        "plt.bar(model.feature_importances_,height=1)"
      ],
      "metadata": {
        "id": "kxlozUChm2lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xdata.columns"
      ],
      "metadata": {
        "id": "xoHyAIpGqRcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "features=xdata.columns\n",
        "\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='maroon', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nzgiq_ODo6Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['dur_min', 'X', 'Y', 'RATING', 'TYPE_corrected_AR', 'TYPE_corrected_IP',\n",
        "       'TYPE_corrected_PC', 'TYPE_corrected_QS', 'ERUPTION_corrected_C',\n",
        "       'ERUPTION_corrected_F', 'ERUPTION_corrected_N', 'ERUPTION_corrected_P',\n",
        "       'TWIST_crctd_A', 'TWIST_crctd_N', 'TWIST_crctd_Y', 'WRITHE_crctd_N',\n",
        "       'WRITHE_crctd_Y', 'THREADS_crctd_N', 'THREADS_crctd_Y',\n",
        "       'CAVITY_corrected_D', 'CAVITY_corrected_N', 'CAVITY_corrected_Y']"
      ],
      "metadata": {
        "id": "SRVB_Kzb3Cs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "   "
      ],
      "metadata": {
        "id": "g1aluYfV3FxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##feature ranking"
      ],
      "metadata": {
        "id": "oQOjTvrVMWub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "C = 4.0; gamma = 0.075;class_weight={1:1}\n",
        "svm = svm.SVC(C=C, gamma=gamma, kernel='rbf',class_weight=class_weight, cache_size=500, max_iter=-1, shrinking=True, tol=1e-8)"
      ],
      "metadata": {
        "id": "bpABPDteMYZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, matplotlib.pylab as plt, matplotlib.mlab as mlab, pandas as pd, requests, urllib, json\n",
        "from datetime import datetime as dt_obj\n",
        "from datetime import timedelta\n",
        "#from sklearn import svm\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "#from sunpy.time import TimeRange\n",
        "#import sunpy.instr.goes\n",
        "from scipy.stats import pearsonr as pearse\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1uvDVIbXMWxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "from sklearn import svm\n",
        "C = 4.0; gamma = 0.075; class_weight = {1:6.5}\n",
        "svm = svm.SVC(C=C, gamma=gamma,probability=True, kernel='rbf',class_weight=class_weight, cache_size=500, max_iter=-1, shrinking=True, tol=1e-8)\n",
        "#XGBOOST\n",
        "import xgboost as xgb\n",
        "XGboost = xgb.XGBClassifier(objective=\"reg:logistic\")\n",
        "#RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF = RandomForestClassifier(n_estimators=100,max_depth=2,class_weight='balanced')\n",
        "#Decisiontree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "DT=DecisionTreeClassifier(class_weight='balanced')\n",
        "\n",
        "#Logisticregression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR=LogisticRegression(class_weight='None')\n",
        "\n",
        "#ELNET\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "ELNET=ElasticNet()\n",
        "\n",
        "#Naivebayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "Bayes = GaussianNB()\n",
        "\n",
        "#Adaboost\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "Adaboost=AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier(n_neighbors=15)\n",
        "\n",
        "#Balanced bagging\n",
        "from imblearn.ensemble import BalancedBaggingClassifier \n",
        "Balancedbagging = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),n_estimators=50,sampling_strategy='auto',replacement=False)\n",
        "\n",
        "#LDA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "LDA = LinearDiscriminantAnalysis(n_components=1)\n",
        "\n",
        "#Gradient boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1)\n"
      ],
      "metadata": {
        "id": "Eehim-vWHekQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method=[svm,XGboost,RF,DT,LR,Bayes,Adaboost,KNN,LDA,GB]"
      ],
      "metadata": {
        "id": "hv9LOsbJHvDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "\tmodels = list()\n",
        "\tmodels.append(LogisticRegression())\n",
        "\tmodels.append(RidgeClassifier())\n",
        "\tmodels.append(SGDClassifier())\n",
        "\tmodels.append(PassiveAggressiveClassifier())\n",
        "\tmodels.append(KNeighborsClassifier())\n",
        "\tmodels.append(DecisionTreeClassifier())\n",
        "\tmodels.append(ExtraTreeClassifier())\n",
        "\tmodels.append(LinearSVC())\n",
        "\tmodels.append(SVC())\n",
        "\tmodels.append(GaussianNB())\n",
        "\tmodels.append(AdaBoostClassifier())\n",
        "\tmodels.append(BaggingClassifier())\n",
        "\tmodels.append(RandomForestClassifier())\n",
        "\tmodels.append(ExtraTreesClassifier())\n",
        "\tmodels.append(GaussianProcessClassifier())\n",
        "\tmodels.append(GradientBoostingClassifier())\n",
        "\tmodels.append(LinearDiscriminantAnalysis())\n",
        "\tmodels.append(QuadraticDiscriminantAnalysis())\n",
        "\treturn models"
      ],
      "metadata": {
        "id": "jshc_8caHx0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def confusion_table(pred, labels):\n",
        "    \"\"\"\n",
        "    computes the number of TP, TN, FP, FN events given the arrays with predictions and true labels\n",
        "    and returns the true skill score\n",
        "  \n",
        "    Args:\n",
        "    pred: np array with predictions (1 for flare, 0 for nonflare)\n",
        "    labels: np array with true labels (1 for flare, 0 for nonflare)\n",
        "  \n",
        "    Returns: true negative, false positive, true positive, false negative\n",
        "    \"\"\"  \n",
        "    Nobs = len(pred)\n",
        "    TN = 0.; TP = 0.; FP = 0.; FN = 0.\n",
        "    for i in range(Nobs):\n",
        "        if (pred[i] == 0 and labels[i] == 0):\n",
        "            TN += 1\n",
        "        elif (pred[i] == 1 and labels[i] == 0):\n",
        "            FP += 1\n",
        "        elif (pred[i] == 1 and labels[i] == 1):\n",
        "            TP += 1 \n",
        "        elif (pred[i] == 0 and labels[i] == 1):\n",
        "            FN += 1\n",
        "        else:\n",
        "            print (\"Error! Observation could not be classified.\")\n",
        "    return TN,FP,TP,FN\n",
        "def plot_confusion_matrix(predicted_labels_list, y_test_list):\n",
        "    cnf_matrix = confusion_matrix(y_test_list, predicted_labels_list)\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
        "    plt.show()\n",
        "def generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n",
        "    if normalize:\n",
        "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cnf_matrix.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
        "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    return cnf_matrix\n",
        "\n",
        "import itertools\n",
        "class_names=[\"without_CME\",\"withCME\"]\n"
      ],
      "metadata": {
        "id": "XmIe80rsH3uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##training and tessting metrics\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "def model_name(model,xdata,ydata):\n",
        "  these_TSS_for_this_k = []\n",
        "  lraccs=[]\n",
        "  recs=[]\n",
        "  precs=[]\n",
        "  recs=[]\n",
        "  TSS_k1_mean=[]\n",
        "  TSS_k1_std=[]\n",
        "  fscore=[]\n",
        "  roc_auc=[]\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import precision_score\n",
        "  from sklearn.metrics import recall_score\n",
        "  from sklearn.metrics import f1_score\n",
        "  from sklearn.metrics import roc_curve\n",
        "  from sklearn.metrics import roc_auc_score\n",
        "  skf = StratifiedKFold(n_splits=10)\n",
        "  for j,i in (skf.split(xdata,ydata)):\n",
        "      train = xdata.iloc[j]; test = xdata.iloc[i]     # test is examples in testing set; train is examples in training set\n",
        "      ytrain = ydata[j]; ytest = ydata[i]\n",
        "      model.fit(train, ytrain)\n",
        "      pred=model.predict(test)\n",
        "      TN,FP,TP,FN = confusion_table(pred, ydata[i])\n",
        "      if (((TP+FN) == 0.0) or (FP+TN)==0.0):\n",
        "          these_TSS_for_this_k.append(-1.0)\n",
        "          continue\n",
        "      else:\n",
        "          these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
        "      print(TN,FP,TP,FN)\n",
        "      lracc = accuracy_score(ytest, pred)\n",
        "      prec = precision_score(ytest, pred)\n",
        "      rec = recall_score(ytest, pred)\n",
        "      lraccs.append(lracc)\n",
        "      precs.append(prec)\n",
        "      recs.append(rec)\n",
        "      \n",
        "      fscore.append(f1_score(ytest,pred))\n",
        "      roc_auc.append(roc_auc_score(ytest,pred))\n",
        "  TSS_k = np.array(these_TSS_for_this_k)\n",
        "\n",
        "  array_of_avg_TSS=np.mean(TSS_k)\n",
        "  array_of_std_TSS=np.std(TSS_k)\n",
        "  TSS_k1_mean.append(array_of_avg_TSS)\n",
        "  TSS_k1_std.append(array_of_std_TSS)\n",
        "  print(\"model_name=\",model)\n",
        "  print(\"The TSS equals\",round(array_of_avg_TSS,2),'+/-',round(array_of_std_TSS,2))\n",
        "  lraccuracy = np.mean(lraccs)\n",
        "  print(\"accscore:\",round(np.mean(lraccs),2),'+/-',round(np.std(lraccs),2))\n",
        "  print(\"Precision:\",round(np.mean(precs),2),'+/-',round(np.std(precs),2))\n",
        "  print(\"REcall:\",round(np.mean(recs),2),'+/-',round(np.std(recs),2))\n",
        "  print(\"F1score:\",round(np.mean(fscore),2),'+/-',round(np.std(fscore),2))\n",
        "  print(\"ROC_AUC:\",round(np.mean(roc_auc),2),'+/-',round(np.std(roc_auc),2))\n",
        "  #plot_confusion_matrix(pred, ytest)\n",
        "  print(\"1-with CME,0-without CME\")"
      ],
      "metadata": {
        "id": "9ZdzBzFJIEhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method=[svm,XGboost,RF,DT,LR,Bayes,Adaboost,KNN,LDA,GB]"
      ],
      "metadata": {
        "id": "KEjYjJmNIIAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(ydata).reshape(820,).shape"
      ],
      "metadata": {
        "id": "7rkIaTuvLfI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name(GB,xdata,np.array(ydata).reshape(820,))"
      ],
      "metadata": {
        "id": "dDaNK529JjVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# creating the dataset\n",
        "label=['svm','RF','DT','LR','Bayes','Adaboost','KNN','LDA','GB']\n",
        "data=[0.35,0.68,0.58,0.67,0.68,0.67,0.66,0.7]\n",
        "err=[0.14,0.14,0.13,0.15,0.14,0.15,0.14,0.16]\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "# creating the bar plot\n",
        "plt.bar(courses, values, color ='maroon',\n",
        "\t\twidth = 0.4)\n",
        "\n",
        "plt.xlabel(\"Courses offered\")\n",
        "plt.ylabel(\"No. of students enrolled\")\n",
        "plt.title(\"Students enrolled in different courses\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DY3gJCEyODi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the dataset\n",
        "label=['svm','RF','DT','LR','Bayes','Adaboost','LDA','GB']\n",
        "data=[0.35,0.68,0.58,0.67,0.68,0.67,0.66,0.7]\n",
        "err=[0.14,0.14,0.13,0.15,0.14,0.15,0.14,0.16]"
      ],
      "metadata": {
        "id": "77lqOJWCPk6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(err)"
      ],
      "metadata": {
        "id": "Z71YTxvrQCep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the plot\n",
        "x_pos=np.arange(len(label))\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(x_pos, np.array(data), yerr=np.array(err), align='center', alpha=0.5, ecolor='black',color='maroon', capsize=10)\n",
        "ax.set_ylabel('True skill score')\n",
        "ax.set_xticks(x_pos)\n",
        "ax.set_xticklabels(label)\n",
        "ax.set_title('TSS of ML models')\n",
        "#ax.yaxis.grid(True)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AjeitrJXO55N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in method:\n",
        "  model_name(i,xdata,np.array(ydata))"
      ],
      "metadata": {
        "id": "YUCjgrhMIIUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xdata"
      ],
      "metadata": {
        "id": "Tf7suBUMIIWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ydata"
      ],
      "metadata": {
        "id": "I8qDhggGIIZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WJzbfjJgIIa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5AkQ88uiIIfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqh-cu0kKMDD"
      },
      "source": [
        "pred_trials=[]\n",
        "pred_orig=[]\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "for j,i in (skf.split(xdata,ydata)):\n",
        "  train = xdata.iloc[j]; test = xdata.iloc[i]     # test is examples in testing set; train is examples in training set\n",
        "  ytrain = ydata.iloc[j]; ytest = ydata.iloc[i]\n",
        "  svm.fit(train, ytrain)\n",
        "  pred=svm.predict(test)\n",
        "  pred_trials.append(pred)\n",
        "  pred_orig.append(ytest)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(pred_trials).T.shape\n",
        "np.array(pred_orig).T.shape"
      ],
      "metadata": {
        "id": "NBgR2DjlVN-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(predicted_labels_list, y_test_list):\n",
        "    cnf_matrix = confusion_matrix(y_test_list, predicted_labels_list)\n",
        "    np.set_printoptions(precision=2)\n",
        "\n",
        "    # Plot non-normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot normalized confusion matrix\n",
        "    plt.figure()\n",
        "    generate_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
        "    plt.show()\n",
        "def generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n",
        "    if normalize:\n",
        "        cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cnf_matrix.max() / 2.\n",
        "\n",
        "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
        "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "    return cnf_matrix\n",
        "\n",
        "import itertools\n",
        "NO_CME=0\n",
        "CME=1\n",
        "class_names=[NO_CME,CME]\n",
        "\n",
        "def confusion_table(pred, labels):\n",
        "    \"\"\"\n",
        "    computes the number of TP, TN, FP, FN events given the arrays with predictions and true labels\n",
        "    and returns the true skill score\n",
        "  \n",
        "    Args:\n",
        "    pred: np array with predictions (1 for flare, 0 for nonflare)\n",
        "    labels: np array with true labels (1 for flare, 0 for nonflare)\n",
        "  \n",
        "    Returns: true negative, false positive, true positive, false negative\n",
        "    \"\"\"  \n",
        "    Nobs = len(pred)\n",
        "    TN = 0.; TP = 0.; FP = 0.; FN = 0.\n",
        "    for i in range(Nobs):\n",
        "        if (pred[i] == 0 and labels[i] == 0):\n",
        "            TN += 1\n",
        "        elif (pred[i] == 1 and labels[i] == 0):\n",
        "            FP += 1\n",
        "        elif (pred[i] == 1 and labels[i] == 1):\n",
        "            TP += 1 \n",
        "        elif (pred[i] == 0 and labels[i] == 1):\n",
        "            FN += 1\n",
        "        else:\n",
        "            print (\"Error! Observation could not be classified.\")\n",
        "    return TN,FP,TP,FN"
      ],
      "metadata": {
        "id": "SXaKiqG5l0KV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "these_TSS_for_this_k = []\n",
        "svmaccs=[]\n",
        "recs=[]\n",
        "precs=[]\n",
        "recs=[]\n",
        "pred_trials=[]\n",
        "pred_orig=[]\n",
        "skf = StratifiedKFold(n_splits=10)\n",
        "for j,i in (skf.split(xdata,ydata)):\n",
        "  train = xdata.iloc[j]; test = xdata.iloc[i]     # test is examples in testing set; train is examples in training set\n",
        "  ytrain = ydata.iloc[j]; ytest = ydata.iloc[i]\n",
        "  svm.fit(train, ytrain)\n",
        "  pred=svm.predict(test)\n",
        "  pred_trials.append(pred)\n",
        "  pred_orig.append(ytest)\n",
        "  TN,FP,TP,FN = confusion_table(pred, np.array(ytest))\n",
        "  if (((TP+FN) == 0.0) or (FP+TN)==0.0):\n",
        "     these_TSS_for_this_k.append(-1.0)\n",
        "     continue\n",
        "  else:\n",
        "     these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
        "  print(TN,FP,TP,FN)\n",
        "  svmacc = accuracy_score(ytest, pred)\n",
        "  prec = precision_score(ytest, pred)\n",
        "  rec = recall_score(ytest, pred)\n",
        "  svmaccs.append(svmacc)\n",
        "  precs.append(prec)\n",
        "  recs.append(rec)\n",
        "TSS_k = np.array(these_TSS_for_this_k)\n",
        "array_of_avg_TSS=np.mean(TSS_k)\n",
        "array_of_std_TSS=np.std(TSS_k)\n",
        "print(\"The TSS equals\",array_of_avg_TSS,'+/-',array_of_std_TSS)\n",
        "svmaccuracy = np.mean(svmaccs)\n",
        "print(\"SVMaccuracy\",np.mean(svmaccs),'+/-',np.std(svmaccs))\n",
        "print(\"SVMprecs\",np.mean(precs),'+/-',np.std(precs))\n",
        "print(\"SVMrecs\",np.mean(recs),'+/-',np.std(recs))\n",
        "plot_confusion_matrix(pred, ytest)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pfoI_3TTVOAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "metrics.plot_roc_curve(svm, test, ytest)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xGucAe7RlRlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xdata.columns"
      ],
      "metadata": {
        "id": "xXKezTEgVOF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for several models\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression()\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def model_training(xdata,ydata_shuffled,model):\n",
        "  these_TSS_for_this_k = []\n",
        "  lraccs=[]\n",
        "  recs=[]\n",
        "  precs=[]\n",
        "  recs=[]\n",
        "  skf = StratifiedKFold(n_splits=10)\n",
        "  for k,(j,i) in enumerate(skf.split(xdata,ydata_shuffled)):\n",
        "      train = xdata[j]; test = xdata[i]     # test is examples in testing set; train is examples in training set\n",
        "      ytrain = ydata_shuffled[j]; ytest = ydata_shuffled[i]   # ytest is labels in testing set; ytrain is labels in training set\n",
        "      model.fit(train, ytrain)\n",
        "      pred = model.predict(test)\n",
        "      TN,FP,TP,FN = confusion_table(pred, ytest)\n",
        "      if (((TP+FN) == 0.0) or (FP+TN)==0.0):\n",
        "          these_TSS_for_this_k.append(-1.0)\n",
        "          continue\n",
        "      else:\n",
        "          these_TSS_for_this_k.append(TP/(TP+FN) - FP/(FP+TN))\n",
        "      print(TN,FP,TP,FN)\n",
        "      lracc = accuracy_score(ytest, pred)\n",
        "      prec = precision_score(ytest, pred)\n",
        "      rec = recall_score(ytest, pred)\n",
        "      lraccs.append(lracc)\n",
        "      precs.append(prec)\n",
        "      recs.append(rec)\n",
        "  TSS_k = np.array(these_TSS_for_this_k)\n",
        "  array_of_avg_TSS=np.mean(TSS_k)\n",
        "  array_of_std_TSS=np.std(TSS_k)\n",
        "  print(\"The TSS equals\",array_of_avg_TSS,'+/-',array_of_std_TSS)\n",
        "  lraccuracy = np.mean(lraccs)\n",
        "  print(np.mean(lraccs),'+/-',np.std(lraccs))\n",
        "  print(np.mean(precs),'+/-',np.std(precs))\n",
        "  print(np.mean(recs),'+/-',np.std(recs))\n",
        "  plot_confusion_matrix(pred, ytest)\n",
        "  metrics.plot_roc_curve(model, test, ytest)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "V9uekUFZVOIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression()\n",
        "model_training(np.array(xdata),np.array(ydata),log_reg)"
      ],
      "metadata": {
        "id": "W7dXoqEFX8vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NAIVEbayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_bayes = GaussianNB()\n",
        "model_training(np.array(xdata),np.array(ydata),naive_bayes)"
      ],
      "metadata": {
        "id": "akBku_oEMW0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adaboost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaboost = AdaBoostClassifier(n_estimators=1000, random_state=0, algorithm='SAMME')\n",
        "model_training(np.array(xdata),np.array(ydata),adaboost)"
      ],
      "metadata": {
        "id": "RlDteT-oMW3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradientboost\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "grboost = GradientBoostingClassifier(loss='exponential',criterion='mae',n_estimators=100)\n",
        "model_training(np.array(xdata),np.array(ydata),grboost)"
      ],
      "metadata": {
        "id": "AzgqpjwKZmmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decisiontree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier(criterion='entropy', splitter='best',max_depth=3)\n",
        "model_training(np.array(xdata),np.array(ydata),dtree)"
      ],
      "metadata": {
        "id": "G1dJqC4candw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest = RandomForestClassifier(n_estimators=100,class_weight='balanced_subsample')\n",
        "model_training(np.array(xdata),np.array(ydata),forest)"
      ],
      "metadata": {
        "id": "vw6rno_EPY3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#balancedbagging\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),sampling_strategy='auto',replacement=False,random_state=0)\n",
        "model_training(np.array(xdata),np.array(ydata),bbc)"
      ],
      "metadata": {
        "id": "Vq8oZVIXPgW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.ensemble import EasyEnsembleClassifier\n",
        "EE = EasyEnsembleClassifier(n_estimators=50)\n",
        "model_training(np.array(xdata),np.array(ydata),EE)"
      ],
      "metadata": {
        "id": "IghX5kJ-PsXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method_names=['SVM','Logistic','NaiveBayes','Adaboost','GRBOOST','DecisionTree','Randomforest']\n",
        "method_scores=[0.77,0.9,0.87,0.9,0.9,0.89,0.87]"
      ],
      "metadata": {
        "id": "kHWkS4AiJp2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(11.5,6))\n",
        "plt.ylim([0.50,1])\n",
        "plt.bar(method_names,method_scores,width=0.4,color='turquoise',edgecolor='black')\n",
        "fig.suptitle('Accuracy Scores', fontsize=20)\n",
        "plt.xlabel('Method Name',fontsize=16)\n",
        "plt.ylabel('Method Score',fontsize=16)\n",
        "\n"
      ],
      "metadata": {
        "id": "nnshTtOKRrfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7,6))\n",
        "plt.xlim([0.50,1])\n",
        "plt.barh(method_names,method_scores,height = 0.5,edgecolor='black')\n",
        "fig.suptitle('Accuracy Scores', fontsize=20)\n",
        "plt.ylabel('Method Name',fontsize=16)\n",
        "plt.xlabel('Method Score',fontsize=16)"
      ],
      "metadata": {
        "id": "CNSqexiuKiuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}